# VLA Integration - Python Dependencies
# Voice Layer
openai-whisper>=20231117
pyaudio>=0.2.13
numpy>=1.24.0

# Cognitive Layer (LLM + Agentic Framework)
langgraph>=0.0.40
langchain>=0.1.0
langchain-openai>=0.0.5
langchain-core>=0.1.0
openai>=1.0.0

# ROS 2 Integration (Optional - Future Extension)
# The MVP uses a pure Python ActionService for execution
# ROS 2 can be added as an optional backend for real robot control
# Install via: sudo apt install ros-humble-rclpy (Ubuntu/Debian)
# or uncomment below for pip installation:
# rclpy

# Data Validation
pydantic>=2.5.0
pydantic-settings>=2.1.0

# Async/Concurrency
aio-pika>=9.3.0  # For async message passing if needed
aiofiles>=23.2.1  # Async file I/O
aiohttp>=3.9.0  # Async HTTP client

# Audio Processing
sounddevice>=0.4.6  # Alternative to PyAudio
scipy>=1.11.0  # Signal processing utilities

# Configuration Management
python-dotenv>=1.0.0
pyyaml>=6.0.1

# Testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-cov>=4.1.0
pytest-mock>=3.12.0

# Linting & Formatting
black>=23.12.0
isort>=5.13.0
mypy>=1.7.0
flake8>=6.1.0

# Type Stubs
types-pyaudio
types-requests

# Logging
structlog>=23.2.0
python-json-logger>=2.0.7

# Utilities
tqdm>=4.66.0  # Progress bars for long operations
click>=8.1.7  # CLI framework
rich>=13.7.0  # Rich console output
orjson>=3.9.0  # Fast JSON serialization
python-dateutil>=2.8.2  # Date/time utilities

# PyTorch (for Whisper GPU support)
# Install separately with: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
# torch>=2.1.0
# torchvision>=0.16.0
# torchaudio>=2.1.0